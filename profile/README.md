## Hi there ðŸ‘‹ This is WhitzardAgent

We are a research group supported by Shanghai Innovation Institute and Fudan University. We are working on the security and safety of LLM-powered agentic systems powered by foundation models.

<img src="https://github.com/user-attachments/assets/c28ce94f-88e6-4815-9762-88eea13f2bad" width="100px">

### Ongoing Projects
#### Agentic Infra
- [**Mirror GUI**](https://github.com/WhitzardAgent/Mirror-GUI) â€” **LLM-based GUI Simulator for Agentic Data Synthesis and Evaluation**
> Mirror GUI is a GUI simulator driven by large language models (LLMs), designed to test and evaluate AI agents interacting with a desktop-like environment. It simulates an Ubuntu-style desktop with application windows, UI elements and a file system so agents can perform GUI actions and researchers can analyze behavior and safety.

#### Agentic Security Toolkits (To be released)
- [**XuanwuBox**](https://github.com/WhitzardAgent/XuanwuBox) - **Your AI security advisor in the Docker runtime for your agentic system**
- [**ThoughtAligner**](https://huggingface.co/fgdrg/Thought-Aligner-7B-v1.0) - **A plug-and-play safety aligner module for your agent's chain-of-thought**
> Are you worried about your AI deleting your important files without asking for permission? Or it just does something unexpected yet dangerous. ThoughtAligner is here for you.
